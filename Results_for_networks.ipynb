{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NHVVJvIuKn-h"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ErsKsbyJzSKs"},"outputs":[],"source":["import os\n","\n","# get to project's folder\n","dirPath = \"/content/drive/MyDrive/Colab Notebooks/Final project/Experiments\"\n","os.chdir(dirPath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OMsytu0iKtje"},"outputs":[],"source":["!pip install tensorflow-addons"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WIKUFenjKtmD"},"outputs":[],"source":["from Data_extraction_transformer import Get_Data\n","from Results import Get_Results\n","\n","import collections\n","import logging\n","#import os already imported in code cell 2\n","import pathlib\n","import re\n","import string\n","import sys\n","import time\n","import math\n","import pickle\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n","\n","import tensorflow_datasets as tfds\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from IPython.display import display, HTML\n","from scipy.io import savemat"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJu3ScdoKtpI"},"outputs":[],"source":["K_SEED = 330\n","\n","class args:\n","\n","  def __init__(self,input_data,roi,net,roi_name,zscore,train_size):\n","    self.input_data = input_data\n","    self.roi = roi\n","    self.net = net\n","    self.roi_name = roi_name\n","    self.K_RUNS = K_RUNS\n","    # preprocessing\n","    self.zscore = zscore\n","    # training parameters\n","    self.train_size = train_size\n","    \n","\n","# data parameters\n","args.input_data = 'data/roi_ts'\n","args.roi = 300\n","args.net = 7\n","args.roi_name = 'roi'\n","args.K_RUNS = 4\n","# preprocessing\n","args.zscore = 1\n","# training parameters\n","args.train_size = 100"]},{"cell_type":"code","source":["#utils functions\n","\n","def _get_clip_labels():\n","    '''\n","    assign all clips within runs a label\n","    use 0 for testretest\n","    '''\n","    # where are the clips within the run?\n","    timing_file = pd.read_csv('data/videoclip_tr_lookup.csv')\n","\n","    clips = []\n","    for run in range(args.K_RUNS):\n","        run_name = 'MOVIE%d' %(run+1) #MOVIEx_7T_yz\n","        timing_df = timing_file[timing_file['run'].str.contains(run_name)]  \n","        timing_df = timing_df.reset_index(drop=True)\n","\n","        for jj, row in timing_df.iterrows():\n","            clips.append(row['clip_name'])\n","            \n","    clip_y = {}\n","    jj = 1\n","    for clip in clips:\n","        if 'testretest' in clip:\n","            clip_y[clip] = 0\n","        else:\n","            clip_y[clip] = jj\n","            jj += 1\n","\n","    return clip_y\n","\n","def GetAcc(model, X, y):\n","  '''\n","  get the confusion matrix and accuracy from the model.predict(X)\n","  inputs: model, X-Eager tensor of data, y-labels\n","  outputs: acc-accuracy\n","  '''\n","\n","  y_hat_hold = model.predict(X)\n","  y_hat = np.argmax(y_hat_hold, axis=2)\n","  true_y = y\n","\n","  y_overtime = []\n","  y_hat_overtime = []\n","  for rows_y,rows_y_hat in zip(true_y,y_hat):\n","    values, counts = np.unique(rows_y, return_counts=True)\n","    ind = np.argmax(counts)\n","    if values[ind] == 15:\n","      counts[ind] = 0\n","      ind = np.argmax(counts)\n","    y_overtime.append(values[ind])\n","\n","    values, counts = np.unique(rows_y_hat, return_counts=True)\n","    ind = np.argmax(counts)\n","    if values[ind] == 15:\n","      counts[ind] = 0\n","      ind = np.argmax(counts)\n","    y_hat_overtime.append(values[ind])\n","\n","  acc = accuracy_score(y_overtime,y_hat_overtime)\n","  return acc\n","\n","def GetMaxInfo(accMat):\n","  '''\n","  findes which layers and heads gave the maximum accuracy\n","  inputs: accMat - matrix of models accuracy where rows are number of heads and columns are number of layers\n","  outputs: maxV - maximum accuracy, headsidx - rows index, layersidx - columns index\n","  '''\n","  maxV = accMat.max().max()\n","  headsidx = np.argmax(np.max(accMat, axis=0), axis=0)\n","  layersidx = np.argmax(np.max(accMat, axis=1), axis=0)\n","  return maxV, headsidx, layersidx\n","\n","def GetAttnDict(X, Model, num_of_clips=len(clip_time) + 3, att_block=5):\n","  '''\n","  builds a dict of summed attention matrices across clips and subjects\n","  inputs: X - Eager tensor, Model- traind model, num_of_clips - number of labels, att_block - which block of attention to take\n","  outputs: att_dict - attention dict of summed attention heads across films and subjects\n","  '''\n","  # att_block can be set to 2-5\n","  mask = Model.layers[0].compute_mask(X)\n","  _, att = Model.layers[att_block]((X))\n","\n","  num_of_subjects = int(X.shape[0]/num_of_clips) # in our case 38 subjects\n","  att_dict = {}\n","  film0_att_ind = []\n","  for j in range(0,num_of_clips):\n","    film_att_ind = [j+i*num_of_clips for i in range(0,num_of_subjects)]\n","    if j<=3:\n","      film0_att_ind += film_att_ind\n","      if j==3:\n","        film0_att_ind = tf.sort(film0_att_ind)\n","        clip_len = tf.reduce_sum(tf.cast(mask[j], tf.int32))\n","        att_dict[f'film{j-3}_att'] = tf.gather(att[:,:,0:clip_len,0:clip_len] , film0_att_ind)\n","    else:\n","      film_att_ind = [j+i*num_of_clips for i in range(0,num_of_subjects)]\n","      clip_len = tf.reduce_sum(tf.cast(mask[j], tf.int32))\n","      att_dict[f'film{j-3}_att'] = tf.gather(att[:,:,0:clip_len,0:clip_len] , film_att_ind)\n","\n","  for j in range(0,num_of_subjects):\n","    subject_att_ind = [j*num_of_clips+i for i in range(0,num_of_clips)]\n","    att_dict[f'subject{j+1}_att'] = tf.gather(att , subject_att_ind)\n","\n","  return att_dict\n","\n","def GetGraphs(att_dict, num_of_clips):\n","  '''\n","  prints attention matrix\n","  inputs: att_dict-dict of attention matrices, num_of_clips - number of labels\n","  outputs: the plots\n","  '''\n","  for j in range(3,num_of_clips):\n","      corr_prepare = att_dict[f'film{j-3}_att']\n","      corr_prepare = tf.reduce_mean(corr_prepare,axis=1)\n","      corr_prepare = np.reshape(corr_prepare, newshape=(corr_prepare.shape[0],-1))\n","      corr_prepare_corrcoef = np.corrcoef(corr_prepare,rowvar=True) # find corr coef for observationXatt\n","\n","      fig = plt.figure()\n","      #fig.set_size_inches(corr_prepare.shape[0]/4, corr_prepare.shape[0]/4)\n","      fig.set_size_inches(152/4, 152/4)\n","      if j==3:\n","        sns.heatmap(corr_prepare_corrcoef)\n","      else:\n","        sns.heatmap(corr_prepare_corrcoef, annot=True)\n","      plt.title(f'film: {clip_names[j-3]} cross subjects corr')\n","      plt.grid()\n","      plt.savefig(RES_DIR + f'/film: {clip_names[j-3]} cross subjects corr')\n","      plt.close('all')\n","\n","def printLoop(net):\n","  print('-----------------------------------------------------------------------------------------------------')\n","  print(f'---------------------------------------------NET: {net}------------------------------------------------')\n","  print('-----------------------------------------------------------------------------------------------------')"],"metadata":{"id":"BhTFATj1A2ki"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z9zuc5ihpBVi"},"outputs":[],"source":["# get clips names\n","clip_y = _get_clip_labels()\n","k_class = len(np.unique(list(clip_y.values())))\n","print('number of classes = %d' %k_class)\n","\n","clip_names = np.zeros(k_class).astype(str)\n","clip_names[0] = 'testretest'\n","for key, item in clip_y.items():\n","    if item!=0:\n","        clip_names[item] = key"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6CmFX2zQKtwP"},"outputs":[],"source":["# get the orginized data from Get_Data function in Data_extraction_transformer.py\n","X_train, train_len, y_train, X_val, val_len, y_val, X_test, test_len, y_test, train_list, test_list, clip_time = Get_Data(args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iDPQndEQCTBD"},"outputs":[],"source":["def GetNetwork(X_train, X_val, X_test,startLH,endLH,startRH,endRH):\n","  '''\n","  sets brain network from right and left hemisphere to X\n","  inputs: X_train,X_val,X_test: Eager tensor with all brain networks\n","          startLH,endLH,startRH,endRH: indices of relevant brain network\n","  outputs: X_train_end,X_val_end,X_test_end: Eager tensor with relevant brain network\n","  '''\n","  X_train_LH = X_train[:,:,startLH:endLH]\n","  X_train_RH = X_train[:,:,startRH:endRH]\n","  X_train_end = tf.concat([X_train_LH, X_train_RH], axis=2)\n","\n","  X_val_LH = X_val[:,:,startLH:endLH]\n","  X_val_RH = X_val[:,:,startRH:endRH]\n","  X_val_end = tf.concat([X_val_LH, X_val_RH], axis=2)\n","\n","  X_test_LH = X_test[:,:,startLH:endLH]\n","  X_test_RH = X_test[:,:,startRH:endRH]\n","  X_test_end = tf.concat([X_test_LH, X_test_RH], axis=2)\n","\n","  return X_train_end, X_val_end, X_test_end\n","\n","networksDict = {'vis':{'startLH':0,'endLH':24,'startRH':151,'endRH':174,'train':[], 'val':[], 'test':[]},\n","                'SomMot':{'startLH':24,'endLH':53,'startRH':174,'endRH':201,'train':[], 'val':[], 'test':[]},\n","                'Attn':{'startLH':53,'endLH':85,'startRH':201,'endRH':237,'train':[], 'val':[], 'test':[]},\n","                'limbic':{'startLH':85,'endLH':95,'startRH':237,'endRH':247,'train':[], 'val':[], 'test':[]},\n","                'Cont':{'startLH':95,'endLH':112,'startRH':247,'endRH':270,'train':[], 'val':[], 'test':[]},\n","                'DMN':{'startLH':112,'endLH':150,'startRH':270,'endRH':300,'train':[], 'val':[], 'test':[]},\n","                'full':{'train':X_train, 'val':X_val, 'test':X_test}\n","                }\n","\n","for net in networksDict:\n","  if net is not 'full':\n","    networksDict[net]['train'], networksDict[net]['val'], networksDict[net]['test'] = GetNetwork(X_train, X_val, X_test, networksDict[net]['startLH'], networksDict[net]['endLH'], networksDict[net]['startRH'], networksDict[net]['endRH'])\n","  print(net + ':')\n","  print('train: '+ str(networksDict[net]['train'].shape))\n","  print('val: '+ str(networksDict[net]['val'].shape))\n","  print('test: '+ str(networksDict[net]['test'].shape))"]},{"cell_type":"code","source":["# Sets results dict for the brain networks\n","\n","modelsDict = {'4 Layers':{'1 Head':None, '4 Heads':None, '6 Heads':None, '8 Heads':None},\n","             '6 Layers':{'1 Head':None, '4 Heads':None, '6 Heads':None, '8 Heads':None},\n","             '8 Layers':{'1 Head':None, '4 Heads':None, '6 Heads':None, '8 Heads':None}}\n","\n","attDict = {'4 Layers':{'1 Head':None, '4 Heads':None, '6 Heads':None, '8 Heads':None},\n","          '6 Layers':{'1 Head':None, '4 Heads':None, '6 Heads':None, '8 Heads':None},\n","          '8 Layers':{'1 Head':None, '4 Heads':None, '6 Heads':None, '8 Heads':None}}\n","\n","networksResults = {\n","    'vis':{'results':{}, 'results_prob':{}, 'acc':np.zeros((3,4)), 'Models':modelsDict, 'att_dict':attDict},\n","    'SomMot':{'results':{}, 'results_prob':{}, 'acc':np.zeros((3,4)), 'Models':modelsDict, 'att_dict':attDict},\n","    'Attn':{'results':{}, 'results_prob':{}, 'acc':np.zeros((3,4)), 'Models':modelsDict, 'att_dict':attDict},\n","    'limbic':{'results':{}, 'results_prob':{}, 'acc':np.zeros((3,4)), 'Models':modelsDict, 'att_dict':attDict},\n","    'Cont':{'results':{}, 'results_prob':{}, 'acc':np.zeros((3,4)), 'Models':modelsDict, 'att_dict':attDict},\n","    'DMN':{'results':{}, 'results_prob':{}, 'acc':np.zeros((3,4)), 'Models':modelsDict, 'att_dict':attDict},\n","    'full':{'results':{}, 'results_prob':{}, 'acc':np.zeros((3,4)), 'Models':modelsDict, 'att_dict':attDict}\n","}"],"metadata":{"id":"ZMk0Rv7i2A1M"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0UCh_n-6dGSN"},"outputs":[],"source":["# set hyperparameters\n","rows_names = ['4 Layers', '6 Layers', '8 Layers']\n","num_layers = [4, 6, 8]\n","rows = len(num_layers)\n","columns_names = ['1 Head', '4 Heads', '6 Heads', '8 Heads']\n","num_heads = [1, 4, 6, 8]\n","columns = len(num_heads)\n","BATCH_SIZE = 64\n","EPOCHS = 45"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qsBpm0aBeEyL"},"outputs":[],"source":["# read results\n","\n","## files paths:\n","# RES_DIR + f'/net: {net} numHeads: {heads} layers: {layers} accuracy', dpi=fig.dpi     # summarize history for accuracy\n","# RES_DIR + f'/net: {net} numHeads: {heads} layers: {layers} loss', dpi=fig.dpi         # summarize history for loss\n","# RES_DIR + f'/net: {net} numHeads: {heads} layers: {layers} Cmat val', dpi=fig.dpi     # val Cmat\n","# RES_DIR + f'/net: {net} numHeads: {heads} layers: {layers} Cmat test', dpi=fig.dpi    # test Cmat\n","# f'/Model_{net}_numHeads_{heads}_num_layers_{layers}'                                  #Models\n","\n","\n","for net in networksResults:\n","  i = j = 0\n","  printLoop(net)\n","  for heads , column in zip(num_heads, columns_names):\n","    for layers, row in zip(num_layers, rows_names):\n","      print(f'---------------------------NET: {net}  number of heads: {heads} number of layers: {layers}--------------------------')\n","\n","      # results directory\n","      RES_DIR = f'{dirPath}/results/encoder/{net}/to sort'\n","      RES_DIR_MODEL = f'{dirPath}/models/encoder_models/{net}'\n","\n","      res_path = (RES_DIR + \n","                  '/%s_%d_net_%s' %(args.roi_name, args.roi, net) +\n","                  '_k_layers_%d' %(layers) +\n","                  '_heads_%d_batch_size_%d' %(heads, BATCH_SIZE) +\n","                  '_num_epochs_%d.pkl' %(EPOCHS))\n","\n","      # load results\n","      with open(res_path ,\"rb\") as  f:\n","          networksResults[net]['results'], networksResults[net]['results_prob'] = pickle.load(f)   \n","\n","      # load model\n","      networksResults[net]['Models'][row][column] = keras.models.load_model(f'{RES_DIR_MODEL}/Model_{net}_numHeads_{heads}_num_layers_{layers}')\n","\n","      # acc matrix\n","      networksResults[net]['acc'][i,j] = GetAcc(networksResults[net]['Models'][row][column], networksDict[net]['test'], y_test)\n","      i += 1\n","    i = 0\n","    j += 1\n","  \n","  networksResults[net]['df'] = pd.DataFrame(data=networksResults[net]['acc'], index=rows_names, columns=columns_names)\n"]},{"cell_type":"code","source":["# get acc for networks\n","\n","for net in networksResults:\n","  printLoop(net)\n","  \n","  # results directory\n","  RES_DIR = f'{dirPath}/results/encoder/{net}'\n","  if not os.path.exists(RES_DIR):\n","      os.makedirs(RES_DIR)\n","\n","  maxV, headsidx, layersidx = GetMaxInfo(networksResults[net]['acc'])\n","  display(networksResults[net]['df'].style.highlight_max(color = 'orange', axis=None))\n","  networksResults[net]['df'].plot(kind='bar', title=f'{net}: max acc: {maxV:.3} for: {columns_names[headsidx]}, {rows_names[layersidx]}', figsize=(8,6), ylim=(0,1.2))\n","  plt.savefig(RES_DIR + f'/net: {net} accuracy bar')\n","  networksResults[net]['df'].to_csv(RES_DIR + f'/net: {net} accuracy data.csv')"],"metadata":{"id":"oVll_rZwuNwW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get pearson corr\n","num_of_clips=len(clip_time) + 3\n","\n","for net in networksResults:\n","  printLoop(net)\n","  RES_DIR_MODEL = f'{dirPath}/models/encoder_models/{net}'\n","  for layers, row in zip(num_layers, rows_names):\n","    for heads, column in zip(num_heads, columns_names):\n","      # # load model\n","      # networksResults[net]['Models'][row][column] = keras.models.load_model(f'{RES_DIR_MODEL}/Model_{net}_numHeads_{heads}_num_layers_{layers}')\n","      Model = keras.models.load_model(f'{RES_DIR_MODEL}/Model_{net}_numHeads_{heads}_num_layers_{layers}')\n","      for att_block in range(2,layers+2):\n","        print(f'-------------------NET: {net}  number of heads: {heads} number of layers: {layers} att: {att_block-1}--------------------')\n","        # # attention dict\n","        # networksResults[net]['att_dict'][row][column] = GetAttnDict(networksDict[net]['val'], networksResults[net]['Models'][row][column], att_block=att_block)\n","        att_dict = GetAttnDict(networksDict[net]['val'], Model, att_block=att_block)\n","\n","\n","        # results directory\n","        RES_DIR = f'{dirPath}/results/encoder/{net}/{row}/{column}/att_block_num_{att_block-1}'\n","        if not os.path.exists(RES_DIR):\n","            os.makedirs(RES_DIR)\n","\n","        GetGraphs(att_dict, num_of_clips)\n"],"metadata":{"id":"P4_qfyDNyph4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get pearson corr histogram\n","num_of_clips=len(clip_time) + 3\n","\n","for net in networksResults:\n","  printLoop(net)\n","  RES_DIR_MODEL = f'{dirPath}/models/encoder_models/{net}'\n","  for layers, row in zip(num_layers, rows_names):\n","    for heads , column in zip(num_heads, columns_names):\n","      # load model\n","      networksResults[net]['Models'][row][column] = keras.models.load_model(f'{RES_DIR_MODEL}/Model_{net}_numHeads_{heads}_num_layers_{layers}')\n","      for att_block in range(2,layers+2):\n","        print(f'-------------------NET: {net}  number of heads: {heads} number of layers: {layers} att: {att_block-1}--------------------')\n","        # attention dict\n","        networksResults[net]['att_dict'][row][column] = GetAttnDict(networksDict[net]['val'], networksResults[net]['Models'][row][column], att_block=att_block)\n","      \n","        # results directory\n","        RES_DIR = f'{dirPath}/results/encoder/{net}/{row}/{column}/att_block_num_{att_block-1}'\n","        if not os.path.exists(RES_DIR):\n","            os.makedirs(RES_DIR)\n","\n","        for j in range(3,num_of_clips):\n","          corr_prepare = networksResults[net]['att_dict'][row][column][f'film{j-3}_att']\n","          corr_prepare = tf.reduce_mean(corr_prepare,axis=1)\n","          corr_prepare = np.reshape(corr_prepare, newshape=(corr_prepare.shape[0],-1))\n","          corr_prepare_corrcoef = np.corrcoef(corr_prepare,rowvar=True) # find corr coef for observationXatt\n","          corr_prepare_corrcoef_hist = np.reshape(corr_prepare_corrcoef, newshape=-1)\n","          corr_prepare_corrcoef_hist = corr_prepare_corrcoef_hist[corr_prepare_corrcoef_hist < 0.98]\n","\n","          fig = plt.figure()\n","          #fig.set_size_inches(corr_prepare.shape[0]/4, corr_prepare.shape[0]/4)\n","          #fig.set_size_inches(152/4, 152/4)\n","          if j==3:\n","            sns.histplot(corr_prepare_corrcoef_hist)\n","          else:\n","            sns.histplot(corr_prepare_corrcoef_hist)\n","          plt.title(f'film: {clip_names[j-3]} hist\\nmax: {corr_prepare_corrcoef_hist.max():.3}\\nmin: {corr_prepare_corrcoef_hist.min():.3}')\n","          plt.savefig(RES_DIR + f'/film: {clip_names[j-3]} cross subjects corr hist')\n","          # plt.show()\n","          plt.close()"],"metadata":{"id":"rSn1-rxjdVoS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get att heads\n","num_of_clips=len(clip_time) + 3\n","\n","for net in networksResults:\n","  printLoop(net)\n","  RES_DIR_MODEL = f'{dirPath}/models/encoder_models/{net}'\n","  for layers, row in zip(num_layers, rows_names):\n","    for heads , column in zip(num_heads, columns_names):\n","      # load model\n","      networksResults[net]['Models'][row][column] = keras.models.load_model(f'{RES_DIR_MODEL}/Model_{net}_numHeads_{heads}_num_layers_{layers}')\n","      for att_block in range(2,layers+2):\n","        print(f'-------------------NET: {net}  number of heads: {heads} number of layers: {layers} att: {att_block-1}--------------------')\n","        # attention dict\n","        networksResults[net]['att_dict'][row][column] = GetAttnDict(networksDict[net]['val'], networksResults[net]['Models'][row][column], att_block=att_block)\n","      \n","        # results directory\n","        RES_DIR = f'{dirPath}/results/encoder/{net}/{row}/{column}/att_block_num_{att_block-1}'\n","        if not os.path.exists(RES_DIR):\n","            os.makedirs(RES_DIR)\n","\n","        for j in range(3,num_of_clips):\n","          att_prepare = networksResults[net]['att_dict'][row][column][f'film{j-3}_att']\n","          att = tf.reduce_mean(att_prepare,axis=1)\n","          att = tf.reduce_mean(att,axis=0)\n","          clip_len = clip_time[j-3]\n","          \n","          # savemat(RES_DIR + f'/film: {clip_names[j-3]} cross subjects mean attention.mat', {'att':np.asarray(att[0:clip_len,0:clip_len])})\n","\n","          fig = plt.figure()\n","          fig.set_size_inches(clip_len/4, clip_len/4)\n","          ax = plt.gca()\n","          ax.matshow(att)\n","          ax.set_xticks(range(clip_len))\n","          ax.set_yticks(range(clip_len))\n","          labels = range(1,clip_len+1)\n","          ax.set_xticklabels(labels, rotation=90)\n","          ax.set_yticklabels(labels)\n","          plt.title(f'film: {clip_names[j-3]} mean attention ')\n","          plt.grid()\n","          plt.savefig(RES_DIR + f'/film: {clip_names[j-3]} cross subjects mean attention')\n","          # plt.show()\n","          plt.close()\n"],"metadata":{"id":"wgikj0EESl4k"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}