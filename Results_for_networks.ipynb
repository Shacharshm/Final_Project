{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18154,"status":"ok","timestamp":1650002190743,"user":{"displayName":"Shachar Shmueli","userId":"13712970895739115524"},"user_tz":-180},"id":"NHVVJvIuKn-h","outputId":"d332aacb-8c0a-4ac1-807d-d6a3f9b4dd5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ErsKsbyJzSKs"},"outputs":[],"source":["import os\n","\n","## shachar\n","dirPath = \"/content/drive/MyDrive/Colab Notebooks/Final project/Experiments\"\n","## ariel\n","# dirPath = \"/content/drive/MyDrive/Colab Notebooks/Experiments\"\n","\n","os.chdir(dirPath)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4057,"status":"ok","timestamp":1650002195792,"user":{"displayName":"Shachar Shmueli","userId":"13712970895739115524"},"user_tz":-180},"id":"OMsytu0iKtje","outputId":"c83d3a3b-0f7d-4b45-a018-159f392a10c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 440 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 471 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 522 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 552 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 604 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 634 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 686 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 716 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 747 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 768 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 798 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 829 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 849 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 880 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 931 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 942 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 962 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 993 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.16.1\n"]}],"source":["!pip install tensorflow-addons"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WIKUFenjKtmD"},"outputs":[],"source":["from Data_extraction_transformer import Get_Data\n","from Results import Get_Results\n","\n","import collections\n","import logging\n","import os\n","import pathlib\n","import re\n","import string\n","import sys\n","import time\n","import math\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","import tensorflow_datasets as tfds\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJu3ScdoKtpI"},"outputs":[],"source":["K_SEED = 330\n","\n","class args:\n","\n","  def __init__(self,input_data,roi,net,roi_name,zscore,train_size):\n","    self.input_data = input_data\n","    self.roi = roi\n","    self.net = net\n","    self.roi_name = roi_name\n","    self.K_RUNS = K_RUNS\n","    # preprocessing\n","    self.zscore = zscore\n","    # training parameters\n","    self.train_size = train_size\n","    \n","\n","# data parameters\n","args.input_data = 'data/roi_ts'\n","args.roi = 300\n","args.net = 7\n","args.roi_name = 'roi'\n","args.K_RUNS = 4\n","# preprocessing\n","args.zscore = 1\n","# training parameters\n","args.train_size = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":551,"status":"ok","timestamp":1650002206725,"user":{"displayName":"Shachar Shmueli","userId":"13712970895739115524"},"user_tz":-180},"id":"z9zuc5ihpBVi","outputId":"caf2ec74-d51a-4389-d9c5-8781e99d6cbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["number of classes = 15\n"]}],"source":["def _get_clip_labels():\n","    '''\n","    assign all clips within runs a label\n","    use 0 for testretest\n","    '''\n","    # where are the clips within the run?\n","    timing_file = pd.read_csv('data/videoclip_tr_lookup.csv')\n","\n","    clips = []\n","    for run in range(args.K_RUNS):\n","        run_name = 'MOVIE%d' %(run+1) #MOVIEx_7T_yz\n","        timing_df = timing_file[timing_file['run'].str.contains(run_name)]  \n","        timing_df = timing_df.reset_index(drop=True)\n","\n","        for jj, row in timing_df.iterrows():\n","            clips.append(row['clip_name'])\n","            \n","    clip_y = {}\n","    jj = 1\n","    for clip in clips:\n","        if 'testretest' in clip:\n","            clip_y[clip] = 0\n","        else:\n","            clip_y[clip] = jj\n","            jj += 1\n","\n","    return clip_y\n","\n","clip_y = _get_clip_labels()\n","k_class = len(np.unique(list(clip_y.values())))\n","print('number of classes = %d' %k_class)\n","\n","clip_names = np.zeros(k_class).astype(str)\n","clip_names[0] = 'testretest'\n","for key, item in clip_y.items():\n","    if item!=0:\n","        clip_names[item] = key"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213940,"status":"ok","timestamp":1650002420650,"user":{"displayName":"Shachar Shmueli","userId":"13712970895739115524"},"user_tz":-180},"id":"6CmFX2zQKtwP","outputId":"7f43536d-679d-4d27-debc-91476bfef3cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["---\n","roi\n","---\n","1\n","1\n","---\n","Number of hyperparameter combinations: 1\n","---\n","---\n","roi\n","---\n","loading run 1/4\n","loading run 2/4\n","loading run 3/4\n","loading run 4/4\n","data loading time: 175.54 seconds\n","number of subjects = 176\n","number of features = 300\n","number of classes = 15\n","seq lengths = [ 84 245 222 189  65 227 260 250 181 186 205 143 233 231 256]\n"]}],"source":["X_train, train_len, y_train, X_val, val_len, y_val, X_test, test_len, y_test, train_list, test_list, clip_time = Get_Data(args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iDPQndEQCTBD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650002420651,"user_tz":-180,"elapsed":14,"user":{"displayName":"Shachar Shmueli","userId":"13712970895739115524"}},"outputId":"54fc2161-f092-4d96-a9ce-c2ac7a464918"},"outputs":[{"output_type":"stream","name":"stdout","text":["vis:\n","train: (1800, 260, 47)\n","val: (684, 260, 47)\n","test: (684, 260, 47)\n","SomMot:\n","train: (1800, 260, 56)\n","val: (684, 260, 56)\n","test: (684, 260, 56)\n","Attn:\n","train: (1800, 260, 68)\n","val: (684, 260, 68)\n","test: (684, 260, 68)\n","limbic:\n","train: (1800, 260, 20)\n","val: (684, 260, 20)\n","test: (684, 260, 20)\n","Cont:\n","train: (1800, 260, 40)\n","val: (684, 260, 40)\n","test: (684, 260, 40)\n","DMN:\n","train: (1800, 260, 68)\n","val: (684, 260, 68)\n","test: (684, 260, 68)\n","full:\n","train: (1800, 260, 300)\n","val: (684, 260, 300)\n","test: (684, 260, 300)\n"]}],"source":["def GetNetwork(X_train, X_val, X_test,startLH,endLH,startRH,endRH):\n","  X_train_LH = X_train[:,:,startLH:endLH]\n","  X_train_RH = X_train[:,:,startRH:endRH]\n","  X_train_end = tf.concat([X_train_LH, X_train_RH], axis=2)\n","\n","  X_val_LH = X_val[:,:,startLH:endLH]\n","  X_val_RH = X_val[:,:,startRH:endRH]\n","  X_val_end = tf.concat([X_val_LH, X_val_RH], axis=2)\n","\n","  X_test_LH = X_test[:,:,startLH:endLH]\n","  X_test_RH = X_test[:,:,startRH:endRH]\n","  X_test_end = tf.concat([X_test_LH, X_test_RH], axis=2)\n","\n","  return X_train_end, X_val_end, X_test_end\n","\n","networksDict = {'vis':{'startLH':0,'endLH':24,'startRH':151,'endRH':174,'train':[], 'val':[], 'test':[]},\n","                'SomMot':{'startLH':24,'endLH':53,'startRH':174,'endRH':201,'train':[], 'val':[], 'test':[]},\n","                'Attn':{'startLH':53,'endLH':85,'startRH':201,'endRH':237,'train':[], 'val':[], 'test':[]},\n","                'limbic':{'startLH':85,'endLH':95,'startRH':237,'endRH':247,'train':[], 'val':[], 'test':[]},\n","                'Cont':{'startLH':95,'endLH':112,'startRH':247,'endRH':270,'train':[], 'val':[], 'test':[]},\n","                'DMN':{'startLH':112,'endLH':150,'startRH':270,'endRH':300,'train':[], 'val':[], 'test':[]},\n","                'full':{'train':X_train, 'val':X_val, 'test':X_test}\n","                }\n","\n","for net in networksDict:\n","  if net is not 'full':\n","    networksDict[net]['train'], networksDict[net]['val'], networksDict[net]['test'] = GetNetwork(X_train, X_val, X_test, networksDict[net]['startLH'], networksDict[net]['endLH'], networksDict[net]['startRH'], networksDict[net]['endRH'])\n","  print(net + ':')\n","  print('train: '+ str(networksDict[net]['train'].shape))\n","  print('val: '+ str(networksDict[net]['val'].shape))\n","  print('test: '+ str(networksDict[net]['test'].shape))"]},{"cell_type":"code","source":["modelsSet = {'4 Layers':{'1 Head':None, '4 Heads':None, '6 Heads':None, '8 Heads':None},\n","             '6 Layers':{'1 Head':None, '4 Heads':None, '6 Heads':None, '8 Heads':None},\n","             '8 Layers':{'1 Head':None, '4 Heads':None, '6 Heads':None, '8 Heads':None}}\n","\n","attSet = {'4 Layers':{'1 Head':None, '4 Heads':None, '6 Heads':None, '8 Heads':None},\n","          '6 Layers':{'1 Head':None, '4 Heads':None, '6 Heads':None, '8 Heads':None},\n","          '8 Layers':{'1 Head':None, '4 Heads':None, '6 Heads':None, '8 Heads':None}}\n","\n","networksResults = {\n","    'vis':{'results':{}, 'results_prob':{}, 'acc':np.zeros((3,4)), 'Models':modelsSet, 'att_dict':attSet},\n","    'SomMot':{'results':{}, 'results_prob':{}, 'acc':np.zeros((3,4)), 'Models':modelsSet, 'att_dict':attSet},\n","    'Attn':{'results':{}, 'results_prob':{}, 'acc':np.zeros((3,4)), 'Models':modelsSet, 'att_dict':attSet},\n","    'limbic':{'results':{}, 'results_prob':{}, 'acc':np.zeros((3,4)), 'Models':modelsSet, 'att_dict':attSet},\n","    'Cont':{'results':{}, 'results_prob':{}, 'acc':np.zeros((3,4)), 'Models':modelsSet, 'att_dict':attSet},\n","    'DMN':{'results':{}, 'results_prob':{}, 'acc':np.zeros((3,4)), 'Models':modelsSet, 'att_dict':attSet},\n","    'full':{'results':{}, 'results_prob':{}, 'acc':np.zeros((3,4)), 'Models':modelsSet, 'att_dict':attSet}\n","}"],"metadata":{"id":"ZMk0Rv7i2A1M"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0UCh_n-6dGSN"},"outputs":[],"source":["rows_names = ['4 Layers', '6 Layers', '8 Layers']\n","num_layers = [4, 6, 8]\n","rows = len(num_layers)\n","columns_names = ['1 Head', '4 Heads', '6 Heads', '8 Heads']\n","num_heads = [1, 4, 6, 8]\n","columns = len(num_heads)\n","BATCH_SIZE = 64\n","EPOCHS = 45"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qsBpm0aBeEyL"},"outputs":[],"source":["### read results\n","\n","import pickle\n","import pandas as pd\n","from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n","\n","## files paths:\n","# RES_DIR + f'/net: {net} numHeads: {heads} layers: {layers} accuracy', dpi=fig.dpi     # summarize history for accuracy\n","# RES_DIR + f'/net: {net} numHeads: {heads} layers: {layers} loss', dpi=fig.dpi         # summarize history for loss\n","# RES_DIR + f'/net: {net} numHeads: {heads} layers: {layers} Cmat val', dpi=fig.dpi     # val Cmat\n","# RES_DIR + f'/net: {net} numHeads: {heads} layers: {layers} Cmat test', dpi=fig.dpi    # test Cmat\n","# f'/Model_{net}_numHeads_{heads}_num_layers_{layers}'                                  #Models\n","\n","\n","def printLoop(net):\n","  print('-----------------------------------------------------------------------------------------------------')\n","  print(f'---------------------------------------------NET: {net}------------------------------------------------')\n","  print('-----------------------------------------------------------------------------------------------------')\n","\n","def GetAcc(model, X, y):\n","  y_hat_hold = model.predict(X)\n","  y_hat = np.argmax(y_hat_hold, axis=2)\n","  true_y = y\n","\n","  y_overtime = []\n","  y_hat_overtime = []\n","  for rows_y,rows_y_hat in zip(true_y,y_hat):\n","    values, counts = np.unique(rows_y, return_counts=True)\n","    ind = np.argmax(counts)\n","    if values[ind] == 15:\n","      counts[ind] = 0\n","      ind = np.argmax(counts)\n","    y_overtime.append(values[ind])\n","\n","    values, counts = np.unique(rows_y_hat, return_counts=True)\n","    ind = np.argmax(counts)\n","    if values[ind] == 15:\n","      counts[ind] = 0\n","      ind = np.argmax(counts)\n","    y_hat_overtime.append(values[ind])\n","\n","  acc = accuracy_score(y_overtime,y_hat_overtime)\n","  return acc\n","\n","def GetMaxInfo(accMat):\n","  maxV = accMat.max().max()\n","  headsidx = np.argmax(np.max(accMat, axis=0), axis=0)\n","  layersidx = np.argmax(np.max(accMat, axis=1), axis=0)\n","  return maxV, headsidx, layersidx\n","\n","for net in networksResults:\n","  i = j = 0\n","  printLoop(net)\n","  for heads , column in zip(num_heads, columns_names):\n","    for layers, row in zip(num_layers, rows_names):\n","      print(f'---------------------------NET: {net}  number of heads: {heads} number of layers: {layers}--------------------------')\n","\n","      # results directory\n","      RES_DIR = f'/content/drive/MyDrive/Colab Notebooks/Final project/Experiments/results/encoder/{net}/to sort'\n","      RES_DIR_MODEL = f'/content/drive/MyDrive/Colab Notebooks/Final project/Experiments/models/encoder_models/{net}'\n","\n","      res_path = (RES_DIR + \n","                  '/%s_%d_net_%s' %(args.roi_name, args.roi, net) +\n","                  '_k_layers_%d' %(layers) +\n","                  '_heads_%d_batch_size_%d' %(heads, BATCH_SIZE) +\n","                  '_num_epochs_%d.pkl' %(EPOCHS))\n","\n","      # load results\n","      with open(res_path ,\"rb\") as  f:\n","          networksResults[net]['results'], networksResults[net]['results_prob'] = pickle.load(f)   \n","\n","      # load model\n","      networksResults[net]['Models'][row][column] = keras.models.load_model(f'{RES_DIR_MODEL}/Model_{net}_numHeads_{heads}_num_layers_{layers}')\n","\n","      # acc matrix\n","      networksResults[net]['acc'][i,j] = GetAcc(networksResults[net]['Models'][row][column], networksDict[net]['test'], y_test)\n","      i += 1\n","    i = 0\n","    j += 1\n","  \n","  networksResults[net]['df'] = pd.DataFrame(data=networksResults[net]['acc'], index=rows_names, columns=columns_names)\n"]},{"cell_type":"code","source":["### get acc for networks\n","\n","from IPython.display import display, HTML\n","\n","def GetMaxInfo(accMat):\n","  maxV = accMat.max().max()\n","  headsidx = np.argmax(np.max(accMat, axis=0), axis=0)\n","  layersidx = np.argmax(np.max(accMat, axis=1), axis=0)\n","  return maxV, headsidx, layersidx\n","\n","for net in networksResults:\n","  printLoop(net)\n","  \n","  # results directory\n","  RES_DIR = f'/content/drive/MyDrive/Colab Notebooks/Final project/Experiments/results/encoder/{net}'\n","  if not os.path.exists(RES_DIR):\n","      os.makedirs(RES_DIR)\n","\n","  maxV, headsidx, layersidx = GetMaxInfo(networksResults[net]['acc'])\n","  display(networksResults[net]['df'].style.highlight_max(color = 'orange', axis=None))\n","  networksResults[net]['df'].plot(kind='bar', title=f'{net}: max acc: {maxV:.3} for: {columns_names[headsidx]}, {rows_names[layersidx]}', figsize=(8,6), ylim=(0,1.2))\n","  plt.savefig(RES_DIR + f'/net: {net} accuracy bar')\n","  networksResults[net]['df'].to_csv(RES_DIR + f'/net: {net} accuracy data.csv')"],"metadata":{"id":"oVll_rZwuNwW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### get pearson corr\n","\n","import seaborn as sns\n","\n","def GetAttnDict(X, Model, num_of_clips=len(clip_time) + 3, att_block=5):\n","  # att_block can be set to 2-5\n","\n","\n","  mask = Model.layers[0].compute_mask(X)\n","  _, att = Model.layers[att_block]((X))\n","\n","\n","  num_of_subjects = int(X.shape[0]/num_of_clips) # in our case 38 subjects\n","  att_dict = {}\n","  film0_att_ind = []\n","  for j in range(0,num_of_clips):\n","    film_att_ind = [j+i*num_of_clips for i in range(0,num_of_subjects)]\n","    if j<=3:\n","      film0_att_ind += film_att_ind\n","      if j==3:\n","        film0_att_ind = tf.sort(film0_att_ind)\n","        clip_len = tf.reduce_sum(tf.cast(mask[j], tf.int32))\n","        att_dict[f'film{j-3}_att'] = tf.gather(att[:,:,0:clip_len,0:clip_len] , film0_att_ind)\n","    else:\n","      film_att_ind = [j+i*num_of_clips for i in range(0,num_of_subjects)]\n","      clip_len = tf.reduce_sum(tf.cast(mask[j], tf.int32))\n","      att_dict[f'film{j-3}_att'] = tf.gather(att[:,:,0:clip_len,0:clip_len] , film_att_ind)\n","\n","  for j in range(0,num_of_subjects):\n","    subject_att_ind = [j*num_of_clips+i for i in range(0,num_of_clips)]\n","    att_dict[f'subject{j+1}_att'] = tf.gather(att , subject_att_ind)\n","\n","  return att_dict\n","\n","def printLoop(net):\n","  print('-----------------------------------------------------------------------------------------------------')\n","  print(f'---------------------------------------------NET: {net}------------------------------------------------')\n","  print('-----------------------------------------------------------------------------------------------------')\n","\n","def GetGraphs(att_dict, num_of_clips):\n","  for j in range(3,num_of_clips):\n","      corr_prepare = att_dict[f'film{j-3}_att']\n","      corr_prepare = tf.reduce_mean(corr_prepare,axis=1)\n","      corr_prepare = np.reshape(corr_prepare, newshape=(corr_prepare.shape[0],-1))\n","      corr_prepare_corrcoef = np.corrcoef(corr_prepare,rowvar=True) # find corr coef for observationXatt\n","\n","      fig = plt.figure()\n","      #fig.set_size_inches(corr_prepare.shape[0]/4, corr_prepare.shape[0]/4)\n","      fig.set_size_inches(152/4, 152/4)\n","      if j==3:\n","        sns.heatmap(corr_prepare_corrcoef)\n","      else:\n","        sns.heatmap(corr_prepare_corrcoef, annot=True)\n","      plt.title(f'film: {clip_names[j-3]} cross subjects corr')\n","      plt.grid()\n","      plt.savefig(RES_DIR + f'/film: {clip_names[j-3]} cross subjects corr')\n","      plt.close('all')\n","\n","num_of_clips=len(clip_time) + 3\n","\n","\n","\n","for net in networksResults:\n","  printLoop(net)\n","  RES_DIR_MODEL = f'/content/drive/MyDrive/Colab Notebooks/Final project/Experiments/models/encoder_models/{net}'\n","  for layers, row in zip(num_layers, rows_names):\n","    for heads, column in zip(num_heads, columns_names):\n","      # # load model\n","      # networksResults[net]['Models'][row][column] = keras.models.load_model(f'{RES_DIR_MODEL}/Model_{net}_numHeads_{heads}_num_layers_{layers}')\n","      Model = keras.models.load_model(f'{RES_DIR_MODEL}/Model_{net}_numHeads_{heads}_num_layers_{layers}')\n","      for att_block in range(2,layers+2):\n","        print(f'-------------------NET: {net}  number of heads: {heads} number of layers: {layers} att: {att_block-1}--------------------')\n","        # # attention dict\n","        # networksResults[net]['att_dict'][row][column] = GetAttnDict(networksDict[net]['val'], networksResults[net]['Models'][row][column], att_block=att_block)\n","        att_dict = GetAttnDict(networksDict[net]['val'], Model, att_block=att_block)\n","\n","\n","        # results directory\n","        RES_DIR = f'/content/drive/MyDrive/Colab Notebooks/Final project/Experiments/results/encoder/{net}/{row}/{column}/att_block_num_{att_block-1}'\n","        if not os.path.exists(RES_DIR):\n","            os.makedirs(RES_DIR)\n","\n","        GetGraphs(att_dict, num_of_clips)\n"],"metadata":{"id":"P4_qfyDNyph4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### get pearson corr histogram\n","\n","import seaborn as sns\n","\n","num_of_clips=len(clip_time) + 3\n","\n","def GetAttnDict(X, Model, num_of_clips=len(clip_time) + 3, att_block=5):\n","\n","\n","  mask = Model.layers[0].compute_mask(X)\n","  _, att = Model.layers[att_block]((X))\n","\n","\n","  num_of_subjects = int(X.shape[0]/num_of_clips) # in our case 38 subjects\n","  att_dict = {}\n","  film0_att_ind = []\n","  for j in range(0,num_of_clips):\n","    film_att_ind = [j+i*num_of_clips for i in range(0,num_of_subjects)]\n","    if j<=3:\n","      film0_att_ind += film_att_ind\n","      if j==3:\n","        film0_att_ind = tf.sort(film0_att_ind)\n","        clip_len = tf.reduce_sum(tf.cast(mask[j], tf.int32))\n","        att_dict[f'film{j-3}_att'] = tf.gather(att[:,:,0:clip_len,0:clip_len] , film0_att_ind)\n","    else:\n","      film_att_ind = [j+i*num_of_clips for i in range(0,num_of_subjects)]\n","      clip_len = tf.reduce_sum(tf.cast(mask[j], tf.int32))\n","      att_dict[f'film{j-3}_att'] = tf.gather(att[:,:,0:clip_len,0:clip_len] , film_att_ind)\n","\n","  for j in range(0,num_of_subjects):\n","    subject_att_ind = [j*num_of_clips+i for i in range(0,num_of_clips)]\n","    att_dict[f'subject{j+1}_att'] = tf.gather(att , subject_att_ind)\n","\n","  return att_dict\n","\n","def printLoop(net):\n","  print('-----------------------------------------------------------------------------------------------------')\n","  print(f'---------------------------------------------NET: {net}------------------------------------------------')\n","  print('-----------------------------------------------------------------------------------------------------')\n","\n","\n","for net in networksResults:\n","  printLoop(net)\n","  RES_DIR_MODEL = f'/content/drive/MyDrive/Colab Notebooks/Final project/Experiments/models/encoder_models/{net}'\n","  for layers, row in zip(num_layers, rows_names):\n","    for heads , column in zip(num_heads, columns_names):\n","      # load model\n","      networksResults[net]['Models'][row][column] = keras.models.load_model(f'{RES_DIR_MODEL}/Model_{net}_numHeads_{heads}_num_layers_{layers}')\n","      for att_block in range(2,layers+2):\n","        print(f'-------------------NET: {net}  number of heads: {heads} number of layers: {layers} att: {att_block-1}--------------------')\n","        # attention dict\n","        networksResults[net]['att_dict'][row][column] = GetAttnDict(networksDict[net]['val'], networksResults[net]['Models'][row][column], att_block=att_block)\n","      \n","        # results directory\n","        RES_DIR = f'/content/drive/MyDrive/Colab Notebooks/Final project/Experiments/results/encoder/{net}/{row}/{column}/att_block_num_{att_block-1}'\n","        if not os.path.exists(RES_DIR):\n","            os.makedirs(RES_DIR)\n","\n","        for j in range(3,num_of_clips):\n","          corr_prepare = networksResults[net]['att_dict'][row][column][f'film{j-3}_att']\n","          corr_prepare = tf.reduce_mean(corr_prepare,axis=1)\n","          corr_prepare = np.reshape(corr_prepare, newshape=(corr_prepare.shape[0],-1))\n","          corr_prepare_corrcoef = np.corrcoef(corr_prepare,rowvar=True) # find corr coef for observationXatt\n","          corr_prepare_corrcoef_hist = np.reshape(corr_prepare_corrcoef, newshape=-1)\n","          corr_prepare_corrcoef_hist = corr_prepare_corrcoef_hist[corr_prepare_corrcoef_hist < 0.98]\n","\n","          fig = plt.figure()\n","          #fig.set_size_inches(corr_prepare.shape[0]/4, corr_prepare.shape[0]/4)\n","          #fig.set_size_inches(152/4, 152/4)\n","          if j==3:\n","            sns.histplot(corr_prepare_corrcoef_hist)\n","          else:\n","            sns.histplot(corr_prepare_corrcoef_hist)\n","          plt.title(f'film: {clip_names[j-3]} hist\\nmax: {corr_prepare_corrcoef_hist.max():.3}\\nmin: {corr_prepare_corrcoef_hist.min():.3}')\n","          plt.savefig(RES_DIR + f'/film: {clip_names[j-3]} cross subjects corr hist')\n","          # plt.show()\n","          plt.close()"],"metadata":{"id":"rSn1-rxjdVoS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### get att heads\n","\n","from scipy.io import savemat\n","\n","num_of_clips=len(clip_time) + 3\n","\n","def GetAttnDict(X, Model, num_of_clips=len(clip_time) + 3, att_block=5):\n","\n","\n","  mask = Model.layers[0].compute_mask(X)\n","  _, att = Model.layers[att_block]((X))\n","\n","\n","  num_of_subjects = int(X.shape[0]/num_of_clips) # in our case 38 subjects\n","  att_dict = {}\n","  film0_att_ind = []\n","  for j in range(0,num_of_clips):\n","    film_att_ind = [j+i*num_of_clips for i in range(0,num_of_subjects)]\n","    if j<=3:\n","      film0_att_ind += film_att_ind\n","      if j==3:\n","        film0_att_ind = tf.sort(film0_att_ind)\n","        clip_len = tf.reduce_sum(tf.cast(mask[j], tf.int32))\n","        att_dict[f'film{j-3}_att'] = tf.gather(att[:,:,0:clip_len,0:clip_len] , film0_att_ind)\n","    else:\n","      film_att_ind = [j+i*num_of_clips for i in range(0,num_of_subjects)]\n","      clip_len = tf.reduce_sum(tf.cast(mask[j], tf.int32))\n","      att_dict[f'film{j-3}_att'] = tf.gather(att[:,:,0:clip_len,0:clip_len] , film_att_ind)\n","\n","  for j in range(0,num_of_subjects):\n","    subject_att_ind = [j*num_of_clips+i for i in range(0,num_of_clips)]\n","    att_dict[f'subject{j+1}_att'] = tf.gather(att , subject_att_ind)\n","\n","  return att_dict\n","\n","def printLoop(net):\n","  print('-----------------------------------------------------------------------------------------------------')\n","  print(f'---------------------------------------------NET: {net}------------------------------------------------')\n","  print('-----------------------------------------------------------------------------------------------------')\n","\n","for net in networksResults:\n","  printLoop(net)\n","  RES_DIR_MODEL = f'/content/drive/MyDrive/Colab Notebooks/Final project/Experiments/models/encoder_models/{net}'\n","  for layers, row in zip(num_layers, rows_names):\n","    for heads , column in zip(num_heads, columns_names):\n","      # load model\n","      networksResults[net]['Models'][row][column] = keras.models.load_model(f'{RES_DIR_MODEL}/Model_{net}_numHeads_{heads}_num_layers_{layers}')\n","      for att_block in range(2,layers+2):\n","        print(f'-------------------NET: {net}  number of heads: {heads} number of layers: {layers} att: {att_block-1}--------------------')\n","        # attention dict\n","        networksResults[net]['att_dict'][row][column] = GetAttnDict(networksDict[net]['val'], networksResults[net]['Models'][row][column], att_block=att_block)\n","      \n","        # results directory\n","        RES_DIR = f'/content/drive/MyDrive/Colab Notebooks/Final project/Experiments/results/encoder/{net}/{row}/{column}/att_block_num_{att_block-1}'\n","        if not os.path.exists(RES_DIR):\n","            os.makedirs(RES_DIR)\n","\n","        for j in range(3,num_of_clips):\n","          att_prepare = networksResults[net]['att_dict'][row][column][f'film{j-3}_att']\n","          att = tf.reduce_mean(att_prepare,axis=1)\n","          att = tf.reduce_mean(att,axis=0)\n","          clip_len = clip_time[j-3]\n","          \n","          # savemat(RES_DIR + f'/film: {clip_names[j-3]} cross subjects mean attention.mat', {'att':np.asarray(att[0:clip_len,0:clip_len])})\n","\n","          fig = plt.figure()\n","          fig.set_size_inches(clip_len/4, clip_len/4)\n","          ax = plt.gca()\n","          ax.matshow(att)\n","          ax.set_xticks(range(clip_len))\n","          ax.set_yticks(range(clip_len))\n","          labels = range(1,clip_len+1)\n","          ax.set_xticklabels(labels, rotation=90)\n","          ax.set_yticklabels(labels)\n","          plt.title(f'film: {clip_names[j-3]} mean attention ')\n","          plt.grid()\n","          plt.savefig(RES_DIR + f'/film: {clip_names[j-3]} cross subjects mean attention')\n","          # plt.show()\n","          plt.close()\n"],"metadata":{"id":"wgikj0EESl4k"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Results_for_networks.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}